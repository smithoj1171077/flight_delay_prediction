{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa8418ba",
   "metadata": {},
   "source": [
    "This notebook is the adjusted version of kaggle author's pre-processing notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62219311",
   "metadata": {},
   "source": [
    "### 1 - Import and concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e94b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "####  Select months and years to exploit (for example)  ####\n",
    "\n",
    "months = ['2023-01', '2023-02', '2023-03']\n",
    "\n",
    "####  Path of your data directory (for example)  ####\n",
    "\n",
    "directory = \" \" \n",
    "\n",
    "# Displaying all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e9106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import and concat df_1 OK\n",
      "import and concat df_2 OK\n",
      "import and concat df_3 OK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>IATA_CODE_Reporting_Airline</th>\n",
       "      <th>Tail_Number</th>\n",
       "      <th>Origin</th>\n",
       "      <th>OriginCityName</th>\n",
       "      <th>Dest</th>\n",
       "      <th>DestCityName</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>Distance</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>9E</td>\n",
       "      <td>N605LR</td>\n",
       "      <td>BDL</td>\n",
       "      <td>Hartford, CT</td>\n",
       "      <td>LGA</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>800</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>2</td>\n",
       "      <td>9E</td>\n",
       "      <td>N605LR</td>\n",
       "      <td>BDL</td>\n",
       "      <td>Hartford, CT</td>\n",
       "      <td>LGA</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>800</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>3</td>\n",
       "      <td>9E</td>\n",
       "      <td>N331PQ</td>\n",
       "      <td>BDL</td>\n",
       "      <td>Hartford, CT</td>\n",
       "      <td>LGA</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>800</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>4</td>\n",
       "      <td>9E</td>\n",
       "      <td>N906XJ</td>\n",
       "      <td>BDL</td>\n",
       "      <td>Hartford, CT</td>\n",
       "      <td>LGA</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>800</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>5</td>\n",
       "      <td>9E</td>\n",
       "      <td>N337PQ</td>\n",
       "      <td>BDL</td>\n",
       "      <td>Hartford, CT</td>\n",
       "      <td>LGA</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>800</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FlightDate  DayOfWeek IATA_CODE_Reporting_Airline Tail_Number Origin  \\\n",
       "0  2023-01-02          1                          9E      N605LR    BDL   \n",
       "1  2023-01-03          2                          9E      N605LR    BDL   \n",
       "2  2023-01-04          3                          9E      N331PQ    BDL   \n",
       "3  2023-01-05          4                          9E      N906XJ    BDL   \n",
       "4  2023-01-06          5                          9E      N337PQ    BDL   \n",
       "\n",
       "  OriginCityName Dest  DestCityName  CRSDepTime  DepDelay  ArrDelay  \\\n",
       "0   Hartford, CT  LGA  New York, NY         800      -3.0     -12.0   \n",
       "1   Hartford, CT  LGA  New York, NY         800      -5.0      -8.0   \n",
       "2   Hartford, CT  LGA  New York, NY         800      -5.0     -21.0   \n",
       "3   Hartford, CT  LGA  New York, NY         800      -6.0     -17.0   \n",
       "4   Hartford, CT  LGA  New York, NY         800      -1.0     -16.0   \n",
       "\n",
       "   Cancelled  Diverted  ActualElapsedTime  Distance  CarrierDelay  \\\n",
       "0        0.0       0.0               56.0     101.0           0.0   \n",
       "1        0.0       0.0               62.0     101.0           0.0   \n",
       "2        0.0       0.0               49.0     101.0           0.0   \n",
       "3        0.0       0.0               54.0     101.0           0.0   \n",
       "4        0.0       0.0               50.0     101.0           0.0   \n",
       "\n",
       "   WeatherDelay  NASDelay  SecurityDelay  LateAircraftDelay  \n",
       "0           0.0       0.0            0.0                0.0  \n",
       "1           0.0       0.0            0.0                0.0  \n",
       "2           0.0       0.0            0.0                0.0  \n",
       "3           0.0       0.0            0.0                0.0  \n",
       "4           0.0       0.0            0.0                0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function initialization\n",
    "\n",
    "def monthly_flight_concat(Month_list, directory_path):\n",
    "\n",
    "    # Initializing an empty dataframe\n",
    "    df_output = pd.DataFrame()\n",
    "\n",
    "    # Repeat for each month in the list\n",
    "    for index, month in enumerate(Month_list, start=1):\n",
    "\n",
    "        # access to the dataset\n",
    "        file_path = f\"{directory_path}[{month}]On_Time_Reporting.csv\"\n",
    "\n",
    "        # Loading the dataset\n",
    "        df = pd.read_csv(file_path,low_memory=False)[['FlightDate', 'DayOfWeek', 'IATA_CODE_Reporting_Airline',\n",
    "                                                      'Tail_Number', 'Origin', 'OriginCityName', 'Dest', 'DestCityName',\n",
    "                                                      'CRSDepTime', 'DepDelay', 'ArrDelay', 'Cancelled', 'Diverted',\n",
    "                                                      'ActualElapsedTime', 'Distance', 'CarrierDelay','WeatherDelay',\n",
    "                                                      'NASDelay', 'SecurityDelay', 'LateAircraftDelay']]\n",
    "\n",
    "        # Adding new collected data\n",
    "        df_output = pd.concat([df_output, df])\n",
    "        print(f'import and concat df_{index} OK')\n",
    "\n",
    "        del df\n",
    "\n",
    "    # replaces null values with 0\n",
    "    df_output = df_output.fillna(0)\n",
    "\n",
    "    # Resetting index after concatenation\n",
    "    df_output.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_output\n",
    "\n",
    "# Function Call\n",
    "df_flight = monthly_flight_concat(months , directory)\n",
    "\n",
    "df_flight.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e58708",
   "metadata": {},
   "source": [
    "### 2 - Pre-processingÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe652fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#time column mapping by category\n",
    "\n",
    "def time_label(column):\n",
    "    labels = ['Night', 'Morning', 'Afternoon', 'Evening']\n",
    "    bins = [0, 600, 1200, 1800, 2400]\n",
    "    column = pd.cut(column, bins=bins, labels=labels, right=False)\n",
    "    return column\n",
    "\n",
    "df_flight['DepTime_label'] = time_label(df_flight['CRSDepTime'])\n",
    "\n",
    "df_flight = df_flight.drop('CRSDepTime', axis = 1)\n",
    "'''\n",
    "# keep \"CRSDepTime\" uncategorised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebe4ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# distance column mapping by category\n",
    "def distance_label(column):\n",
    "    labels = ['Short Haul >1500Mi', 'Medium Haul <3000Mi', 'Long Haul <6000Mi']\n",
    "    bins = [0, 1500, 3000, 6000]\n",
    "    column = pd.cut(column, bins=bins, labels=labels, right=False)\n",
    "    return column\n",
    "\n",
    "df_flight['Distance_label'] = distance_label(df_flight['Distance'])\n",
    "\n",
    "df_flight = df_flight.drop('Distance', axis = 1)\n",
    "'''\n",
    "# keep \"Distance\" uncategorised as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ccc4c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing aberrant values in the 'Tail_Number' column\n",
    "Tail_erreur = ('205NV', '286NV', '222NV', '258NV', '230NV', '261NV',\n",
    "       '325NV', '234NV', '288NV', '291NV', '262NV', '274NV', '329NV',\n",
    "       '203NV', '193NV', '314NV', '219NV', '311NV', '277NV', '315NV',\n",
    "       '240NV', '232NV', '295NV', '290NV', '259NV', '302NV', '191NV',\n",
    "       '273NV', '248NV', '312NV', '306NV', '237NV', '252NV', '292NV',\n",
    "       '279NV', '309NV', '305NV', '289NV', '244NV', '260NV', '293NV',\n",
    "       '307NV', '251NV', '332NV', '247NV', '195NV', '284NV', '238NV',\n",
    "       '239NV', '326NV', '313NV', '301NV', '235NV', '285NV', '223NV',\n",
    "       '241NV', '206NV', '218NV', '310NV', '335NV', '296NV', '220NV',\n",
    "       '282NV', '278NV', '328NV', '215NV', '256NV', '275NV', '204NV',\n",
    "       '322NV', '216NV', '194NV', '202NV', '298NV', '245NV', '231NV',\n",
    "       '209NV', '242NV', '207NV', '299NV', '321NV', '208NV', '324NV',\n",
    "       '287NV', '333NV', '317NV', '190NV', '253NV', '294NV', '257NV',\n",
    "       '229NV', '320NV', '249NV', '338NV', '297NV', '250NV', '276NV',\n",
    "       '272NV', '254NV', '318NV', '224NV', '280NV', '221NV', '337NV',\n",
    "       '327NV', '236NV', '330NV', '255NV', '246NV', '323NV', '243NV',\n",
    "       '199NV', '233NV', '331NV', '283NV', '308NV', '316NV', '281NV',\n",
    "       '319NV', '334NV', '217NV','192NV', '198NV', '196NV','197NV',\n",
    "       'SS1','SS2', 'SS3', '210NV', '211NV', '212NV', 'N8885', '271NV')\n",
    "\n",
    "Tail_correction = ('N205NV', 'N286NV', 'N222NV', 'N258NV', 'N230NV', 'N261NV',\n",
    "       'N325NV', 'N234NV', 'N288NV', 'N291NV', 'N262NV', 'N274NV', 'N329NV',\n",
    "       'N203NV', 'N193NV', 'N314NV', 'N219NV', 'N311NV', 'N277NV', 'N315NV',\n",
    "       'N240NV', 'N232NV', 'N295NV', 'N290NV', 'N259NV', 'N302NV', 'N191NV',\n",
    "       'N273NV', 'N248NV', 'N312NV', 'N306NV', 'N237NV', 'N252NV', 'N292NV',\n",
    "       'N279NV', 'N309NV', 'N305NV', 'N289NV', 'N244NV', 'N260NV', 'N293NV',\n",
    "       'N307NV', 'N251NV', 'N332NV', 'N247NV', 'N195NV', 'N284NV', 'N238NV',\n",
    "       'N239NV', 'N326NV', 'N313NV', 'N301NV', 'N235NV', 'N285NV', 'N223NV',\n",
    "       'N241NV', 'N206NV', 'N218NV', 'N310NV', 'N335NV', 'N296NV', 'N220NV',\n",
    "       'N282NV', 'N278NV', 'N328NV', 'N215NV', 'N256NV', 'N275NV', 'N204NV',\n",
    "       'N322NV', 'N216NV', 'N194NV', 'N202NV', 'N298NV', 'N245NV', 'N231NV',\n",
    "       'N209NV', 'N242NV', 'N207NV', 'N299NV', 'N321NV', 'N208NV', 'N324NV',\n",
    "       'N287NV', 'N333NV', 'N317NV', 'N190NV', 'N253NV', 'N294NV', 'N257NV',\n",
    "       'N229NV', 'N320NV', 'N249NV', 'N338NV', 'N297NV', 'N250NV', 'N276NV',\n",
    "       'N272NV', 'N254NV', 'N318NV', 'N224NV', 'N280NV', 'N221NV', 'N337NV',\n",
    "       'N327NV', 'N236NV', 'N330NV', 'N255NV', 'N246NV', 'N323NV', 'N243NV',\n",
    "       'N199NV', 'N233NV', 'N331NV', 'N283NV', 'N308NV', 'N316NV', 'N281NV',\n",
    "       'N319NV', 'N334NV', 'N217NV', 'N192NV', 'N198NV', 'N196NV','N197NV',\n",
    "       'F-HZEN', 'F-HHUG', 'F-', 'N210NV', 'N211NV', 'N212NV', 'N8885Q', 'N271NV')\n",
    "\n",
    "df_flight['Tail_Number'] = df_flight['Tail_Number'].replace(Tail_erreur,Tail_correction)\n",
    "\n",
    "tails_list = ('N152NK', 'N177NK', 'N135NK', 'N200NK', 'N305NK', 'N105NK')\n",
    "row_drop = df_flight[df_flight['Tail_Number'].isin(tails_list)]\n",
    "df_flight = df_flight.drop(row_drop.index)\n",
    "\n",
    "# deletion of all lines relating to the SS1, SS2, SS3 planes\n",
    "liste = ('SS1','SS2','SS3')\n",
    "drop_list = df_flight[df_flight['Tail_Number'].isin(liste)]\n",
    "df_flight = df_flight.drop(drop_list.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11f54757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added category type column for delays\n",
    "df_flight['Arr_Delay_Type'] = df_flight['ArrDelay'].apply(lambda x : 'Hight >60min' if x > 60 else 'Medium >15min' if x > 15 else 'Low <5min')\n",
    "df_flight['Dep_Delay_Type'] = df_flight['DepDelay'].apply(lambda x : 'Hight >60min' if x > 60 else 'Medium >15min' if x > 15 else 'Low <5min')\n",
    "\n",
    "# added a booleen tag for departure delay \n",
    "df_flight['Dep_Delay_Tag'] = df_flight['DepDelay'].apply(lambda x : 1 if x > 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3735626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compagny convertion\n",
    "Compagny_mapping = {\n",
    "    '9E':'Endeavor Air',\n",
    "    'AA':'American Airlines Inc.',\n",
    "    'AS':'Alaska Airlines Inc.',\n",
    "    'B6':'JetBlue Airways',\n",
    "    'DL':'Delta Air Lines Inc',\n",
    "    'F9':'Frontier Airlines Inc.',\n",
    "    'G4':'Allegiant Air',\n",
    "    'HA':'Hawaiian Airlines Inc.',\n",
    "    'MQ':'American Eagle Airlines Inc.',\n",
    "    'NK':'Spirit Air Lines',\n",
    "    'WN':'Southwest Airlines Co.',\n",
    "    'YX':'Republic Airways',\n",
    "    'OH':'PSA Airlines',\n",
    "    'OO':'Skywest Airlines Inc.',\n",
    "    'UA': 'United Air Lines Inc.'\n",
    "}\n",
    "df_flight['Airline'] = df_flight['IATA_CODE_Reporting_Airline'].map(Compagny_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be857c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# column renaming and ordering\\ncolonnes = {\\n    'FlightDate' : 'FlightDate',\\n    'DayOfWeek' : 'Day_Of_Week',\\n    'Tail_Number' : 'Tail_Number',\\n    'Origin' : 'Dep_Airport',\\n    'OriginCityName' : 'Dep_CityName',\\n    'Dest' : 'Arr_Airport',\\n    'DestCityName' : 'Arr_CityName',\\n    'DepDelay' : 'Dep_Delay',\\n    'ArrDelay':'Arr_Delay',\\n    'Cancelled':'Cancelled',\\n    'Diverted':'Diverted',\\n    'ActualElapsedTime' :'Flight_Duration',\\n    'CarrierDelay' : 'Delay_Carrier',\\n    'WeatherDelay' : 'Delay_Weather',\\n    'NASDelay' : 'Delay_NAS',\\n    'SecurityDelay' : 'Delay_Security',\\n    'LateAircraftDelay' : 'Delay_LastAircraft',\\n    'DepTime_label' : 'DepTime_label',\\n    'Distance_label' : 'Distance_type',\\n    'Dep_Delay_Type' : 'Arr_Delay_Type',\\n    'Dep_Delay_Type' : 'Dep_Delay_Type',\\n    'Dep_Delay_Tag' : 'Dep_Delay_Tag',    \\n    'Airline' : 'Airline'\\n    }\\ndf_flight = df_flight.rename(columns=colonnes)\\n\\n# ordering\\nordre=['FlightDate',\\n       'Day_Of_Week',\\n       'Airline',\\n       'Tail_Number',\\n       'Cancelled',\\n       'Diverted',\\n       'Dep_Airport',\\n       'Dep_CityName',\\n       'DepTime_label',\\n       'Dep_Delay',\\n       'Dep_Delay_Tag',\\n       'Dep_Delay_Type',\\n       'Arr_Airport',\\n       'Arr_CityName',\\n       'Arr_Delay',\\n       'Arr_Delay_Type',\\n       'Flight_Duration',\\n       'Distance_type',\\n       'Delay_Carrier',\\n       'Delay_Weather',\\n       'Delay_NAS',\\n       'Delay_Security',\\n       'Delay_LastAircraft',\\n]\\ndf_flight = df_flight.reindex(columns=ordre)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# column renaming and ordering\n",
    "colonnes = {\n",
    "    'FlightDate' : 'FlightDate',\n",
    "    'DayOfWeek' : 'Day_Of_Week',\n",
    "    'Tail_Number' : 'Tail_Number',\n",
    "    'Origin' : 'Dep_Airport',\n",
    "    'OriginCityName' : 'Dep_CityName',\n",
    "    'Dest' : 'Arr_Airport',\n",
    "    'DestCityName' : 'Arr_CityName',\n",
    "    'DepDelay' : 'Dep_Delay',\n",
    "    'ArrDelay':'Arr_Delay',\n",
    "    'Cancelled':'Cancelled',\n",
    "    'Diverted':'Diverted',\n",
    "    'ActualElapsedTime' :'Flight_Duration',\n",
    "    'CarrierDelay' : 'Delay_Carrier',\n",
    "    'WeatherDelay' : 'Delay_Weather',\n",
    "    'NASDelay' : 'Delay_NAS',\n",
    "    'SecurityDelay' : 'Delay_Security',\n",
    "    'LateAircraftDelay' : 'Delay_LastAircraft',\n",
    "    'DepTime_label' : 'DepTime_label',\n",
    "    'Distance_label' : 'Distance_type',\n",
    "    'Dep_Delay_Type' : 'Arr_Delay_Type',\n",
    "    'Dep_Delay_Type' : 'Dep_Delay_Type',\n",
    "    'Dep_Delay_Tag' : 'Dep_Delay_Tag',    \n",
    "    'Airline' : 'Airline'\n",
    "    }\n",
    "df_flight = df_flight.rename(columns=colonnes)\n",
    "\n",
    "# ordering\n",
    "ordre=['FlightDate',\n",
    "       'Day_Of_Week',\n",
    "       'Airline',\n",
    "       'Tail_Number',\n",
    "       'Cancelled',\n",
    "       'Diverted',\n",
    "       'Dep_Airport',\n",
    "       'Dep_CityName',\n",
    "       'DepTime_label',\n",
    "       'Dep_Delay',\n",
    "       'Dep_Delay_Tag',\n",
    "       'Dep_Delay_Type',\n",
    "       'Arr_Airport',\n",
    "       'Arr_CityName',\n",
    "       'Arr_Delay',\n",
    "       'Arr_Delay_Type',\n",
    "       'Flight_Duration',\n",
    "       'Distance_type',\n",
    "       'Delay_Carrier',\n",
    "       'Delay_Weather',\n",
    "       'Delay_NAS',\n",
    "       'Delay_Security',\n",
    "       'Delay_LastAircraft',\n",
    "]\n",
    "df_flight = df_flight.reindex(columns=ordre)\n",
    "'''\n",
    "\n",
    "# keep the original column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7585a8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# extract and drop 'Cancelled' and 'Diverted' Flights\\nextract_Cancel_Divert = df_flight[(df_flight['Cancelled'] == 1.0) | (df_flight['Diverted'] == 1.0)]\\ndf_flight = df_flight.drop(extract_Cancel_Divert.index)\\n\\n# export Cancelled and Diverted Flights\\nextract_Cancel_Divert.to_csv(f'{directory}Cancelled_Diverted_2023.csv', index=False)\\n\\ndf_flight = df_flight.drop(['Cancelled','Diverted'], axis = 1)\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# extract and drop 'Cancelled' and 'Diverted' Flights\n",
    "extract_Cancel_Divert = df_flight[(df_flight['Cancelled'] == 1.0) | (df_flight['Diverted'] == 1.0)]\n",
    "df_flight = df_flight.drop(extract_Cancel_Divert.index)\n",
    "\n",
    "# export Cancelled and Diverted Flights\n",
    "extract_Cancel_Divert.to_csv(f'{directory}Cancelled_Diverted_2023.csv', index=False)\n",
    "\n",
    "df_flight = df_flight.drop(['Cancelled','Diverted'], axis = 1)\n",
    "'''\n",
    "\n",
    "# keep all flights together for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1dca03",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/xiekeyue/.cache/kagglehub/datasets/bordanova/2023-us-civil-flights-delay-meteo-and-aircraft/versions/9/Aircraft_Manufacturer.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Loading aicraft dataset (in the kaggle dataset)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_aircraft \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/xiekeyue/.cache/kagglehub/datasets/bordanova/2023-us-civil-flights-delay-meteo-and-aircraft/versions/9/Aircraft_Manufacturer.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, usecols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMANUFACTURER\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMODEL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFIRSTFLIGHT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTAILNUMBER\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# renaming columns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df_aircraft \u001b[38;5;241m=\u001b[39m df_aircraft\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMANUFACTURER\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mManufacturer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMODEL\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFIRSTFLIGHT\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirst_Flight\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTAILNUMBER\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTail_Number\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/xiekeyue/.cache/kagglehub/datasets/bordanova/2023-us-civil-flights-delay-meteo-and-aircraft/versions/9/Aircraft_Manufacturer.csv'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Loading aicraft dataset \n",
    "df_aircraft = pd.read_csv(f\"{directory}Aircraft_Manufacturer.csv\", usecols=['MANUFACTURER', 'MODEL', 'FIRSTFLIGHT', 'TAILNUMBER'])\n",
    "\n",
    "# renaming columns\n",
    "df_aircraft = df_aircraft.rename(columns={'MANUFACTURER': 'Manufacturer', 'MODEL': 'Model', 'FIRSTFLIGHT': 'First_Flight', 'TAILNUMBER': 'Tail_Number'})\n",
    "\n",
    "# Adding the age of the plane\n",
    "df_aircraft['Aicraft_age'] = (2024 - df_aircraft['First_Flight'])\n",
    "df_aircraft = df_aircraft.drop('First_Flight', axis = 1)\n",
    "df_aircraft.head(5)\n",
    "'''\n",
    "\n",
    "# This csv is not provided by author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f5535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df_flight = pd.merge(df_flight, df_aircraft, on='Tail_Number', how='left')\n",
    "\n",
    "# modification of the typing of the numeric coloumns into 'int'\n",
    "numeric_columns = df_flight.select_dtypes(include=['float']).columns\n",
    "for col in numeric_columns:\n",
    "    df_flight[col] = df_flight[col].astype(int)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53a5f482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates Convertion\n",
    "df_flight['FlightDate'] = pd.to_datetime(df_flight['FlightDate'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e212c0fe",
   "metadata": {},
   "source": [
    "### 3 - Controls and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35036ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export results\n",
    "df_flight.to_csv(f'{directory}US_flights.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
